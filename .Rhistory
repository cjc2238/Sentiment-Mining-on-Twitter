D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
df$positive <- tm_term_score(tdm.corpus, positive)
df$negative <- tm_term_score(tdm.corpus, negative)
df$score <- df$positive - df$negative
df2 <- df %>% group_by(day) %>% summarise(mean(score))
View(df2)
View(df)
names(df2) <- c("Day", "Score")
ggplot(df2, aes(Day, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
plot(df2)
?searchTwitteR
list <- searchTwitteR('Hillary Clinton', since='2016-10-28', until='2016-11-04', resultType = popular, n=5000)
list <- searchTwitteR('Hillary Clinton', since='2016-10-28', until='2016-11-04', resultType = "popular", n=5000)
list <- searchTwitteR('Hillary Clinton', since='2016-10-28', until='2016-11-04', resultType = "popular", n=50)
df <- twListToDF(list)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
df$created <- as.POSIXct(df$created, tz = "EST")
df$day = as.numeric(format(df$created, format = "%d"))
#####################
# Process the corpus
#####################
D1 <- Corpus(VectorSource(df$text))
D2 <- sapply(D1,function(row) iconv(row, "latin1", "ASCII", sub=""))
## Remove Websites
D3 <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+@", "", D2)
## Remove spammed values by only selecting unique tweets
D5 <- Corpus(VectorSource(D3))
#########################
## Clean the corpus data
#########################
## Remove puncuation
D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
df$positive <- tm_term_score(tdm.corpus, positive)
df$negative <- tm_term_score(tdm.corpus, negative)
df$score <- df$positive - df$negative
#########################################
# Generate graph for sentiment over time
#########################################
## Create data frame to graph
df2 <- df %>% group_by(day) %>% summarise(mean(score))
names(df2) <- c("Day", "Score")
## Plot a line plot using ggplot
ggplot(df2, aes(Day, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
list <- searchTwitteR('Hillary Clinton', since='2016-10-1', until='2016-10-31', resultType = "popular", n=5000)
list <- searchTwitteR('Hillary Clinton', since='2016-10-1', until='2016-10-31', resultType = "mixed", n=5000)
df <- twListToDF(list)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
df$created <- as.POSIXct(df$created, tz = "EST")
df$day = as.numeric(format(df$created, format = "%d"))
#####################
# Process the corpus
#####################
D1 <- Corpus(VectorSource(df$text))
D2 <- sapply(D1,function(row) iconv(row, "latin1", "ASCII", sub=""))
## Remove Websites
D3 <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+@", "", D2)
## Remove spammed values by only selecting unique tweets
D5 <- Corpus(VectorSource(D3))
#########################
## Clean the corpus data
#########################
## Remove puncuation
D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
df$positive <- tm_term_score(tdm.corpus, positive)
df$negative <- tm_term_score(tdm.corpus, negative)
df$score <- df$positive - df$negative
#########################################
# Generate graph for sentiment over time
#########################################
## Create data frame to graph
df2 <- df %>% group_by(day) %>% summarise(mean(score))
names(df2) <- c("Day", "Score")
## Plot a line plot using ggplot
ggplot(df2, aes(Day, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
list6 <- searchTwitteR('Hillary Clinton', since='2016-10-25', until='2016-10-26', resultType = "mixed", n=100)
list7 <- searchTwitteR('Hillary Clinton', since='2016-10-24', until='2016-10-25', resultType = "mixed", n=100)
list6 <- searchTwitteR('Hillary Clinton', since='2016-10-31', until='2016-11-1', resultType = "mixed", n=100)
df6 <- twListToDF(list6)
list7 <- searchTwitteR('Hillary Clinton', since='2016-11-1', until='2016-11-2', resultType = "mixed", n=100)
df7 <- twListToDF(list7)
df <- rbind(df1, df2, df3, df4, df5, df6, df7)
df4 <- twListToDF(list4)
df <- rbind(df1, df2, df3, df4, df5, df6, df7)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
df$created <- as.POSIXct(df$created, tz = "EST")
df$day = as.numeric(format(df$created, format = "%d"))
#####################
# Process the corpus
#####################
D1 <- Corpus(VectorSource(df$text))
D2 <- sapply(D1,function(row) iconv(row, "latin1", "ASCII", sub=""))
## Remove Websites
D3 <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+@", "", D2)
## Remove spammed values by only selecting unique tweets
D5 <- Corpus(VectorSource(D3))
#########################
## Clean the corpus data
#########################
## Remove puncuation
D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
df$positive <- tm_term_score(tdm.corpus, positive)
df$negative <- tm_term_score(tdm.corpus, negative)
df$score <- df$positive - df$negative
#########################################
# Generate graph for sentiment over time
#########################################
## Create data frame to graph
df2 <- df %>% group_by(day) %>% summarise(mean(score))
names(df2) <- c("Day", "Score")
## Plot a line plot using ggplot
ggplot(df2, aes(Day, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
df2 <- df %>% group_by(created) %>% summarise(mean(score))
View(df2)
names(df2) <- c("Date", "Score")
ggplot(df2, aes(Date, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
View(df2)
source('~/GitHub/Sentiment Mining on Twitter/Pull tweets by day.R', echo=TRUE)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
df$created <- as.POSIXct(df$created, tz = "EST")
df$day = as.numeric(format(df$created, format = "%d"))
#####################
# Process the corpus
#####################
D1 <- Corpus(VectorSource(df$text))
D2 <- sapply(D1,function(row) iconv(row, "latin1", "ASCII", sub=""))
## Remove Websites
D3 <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+@", "", D2)
## Remove spammed values by only selecting unique tweets
D5 <- Corpus(VectorSource(D3))
#########################
## Clean the corpus data
#########################
## Remove puncuation
D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
df$positive <- tm_term_score(tdm.corpus, positive)
df$negative <- tm_term_score(tdm.corpus, negative)
df$score <- df$positive - df$negative
#########################################
# Generate graph for sentiment over time
#########################################
## Create data frame to graph
df2 <- df %>% group_by(created) %>% summarise(mean(score))
names(df2) <- c("Date", "Score")
## Plot a line plot using ggplot
ggplot(df2, aes(Date, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
source('~/GitHub/Sentiment Mining on Twitter/Hillary Twitter.R', echo=TRUE)
source('~/GitHub/Sentiment Mining on Twitter/Hillary Twitter.R', echo=TRUE)
hrc2 <- hrc %>% group_by(created) %>% summarise(mean(score))
View(hrc2)
names(hrc2) <- c("Date", "Score")
## Plot a line plot using ggplot
ggplot(hrc2, aes(Date, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, Score)) + geom_line() + xlab("Day") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, Score)) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
hrc2$positive <- hrc %>% group_by(created) %>% summarise(mean(positive))
hrc2$negative <- hrc %>% group_by(created) %>% summarise(mean(negative))
names(hrc2) <- c("Date", "Score","Positive","Negative")
View(hrc)
ggplot()+
geom_line(aes(Date, Score, colour="blue"), hrc2)+
geom_line(aes(Date, Positive, colour="green"), hrc2)+
geom_line(aes(Date, Negative, colour="red"), hrc2)
ggplot(hrc2, aes(Date, c(Score,Positive,Negative)) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, c(Score,Positive,Negative))) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, c(Score,Positive,Negative)) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, Score) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
ggplot(hrc2, aes(Date, Score)) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
hrc2 <- hrc %>% group_by(created) %>% summarise(mean(score))
names(hrc2) <- c("Date", "Score")
hrc3 <- hrc %>% group_by(created) %>% summarise(mean(positive))
names(hrc3) <- c("Date", "Positive")
hrc4 <- hrc %>% group_by(created) %>% summarise(mean(negative))
names(hrc4) <- c("Date","Negative")
## Plot a line plot using ggplot
ggplot() +
geom_line(aes(Date, Score, colour=g1), hrc2) +
geom_line(aes(Date, Positive, colour=g2), hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="blue"), hrc2) +
geom_line(aes(Date, Positive, colour="green"), hrc3)
ggplot() +
geom_line(aes(Date, Score, colour=green), hrc2) +
geom_line(aes(Date, Positive, colour=blue), hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Mean Sentiment Score"), hrc2) +
geom_line(aes(Date, Positive, colour="Positive"),colour=green, hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Mean Sentiment Score"), hrc2) +
geom_line(aes(Date, Positive, colour="Positive"),colour="green", hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Mean Sentiment Score"),colour="blue", hrc2) +
geom_line(aes(Date, Positive, colour="Positive"),colour="green", hrc3)
ggplot() +
geom_line(aes(Date, Score, colour=score),colour="blue", hrc2) +
geom_line(aes(Date, Positive, colour="Positive"),colour="green", hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), hrc2) +
geom_line(aes(Date, Positive, colour="Positive"),colour="green", hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), hrc2) + colour="blue" +
geom_line(aes(Date, Positive, colour="Positive"),colour="green", hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), hrc3)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), hrc4)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), hrc2) +
theme(text = element_text(size=18)) +
geom_line(aes(Date, Positive, colour="Positive"), hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), hrc4)
ggplot() +
geom_line(aes(Date, Score, colour="Score", size = 2), hrc2) +
theme(text = element_text(size=18)) +
geom_line(aes(Date, Positive, colour="Positive"), hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), hrc4)
ggplot() +
geom_line(aes(Date, Score, colour="Score", size = 2), hrc2) +
geom_line(aes(Date, Positive, colour="Positive", size = 2), hrc3) +
geom_line(aes(Date, Negative, colour="Negative", size = 2), hrc4) + theme(text = element_text(size=18))
ggplot() +
geom_line(aes(Date, Score, colour="Score", size = 2), hrc2) +
geom_line(aes(Date, Positive, colour="Positive", size = 2), hrc3) +
geom_line(aes(Date, Negative, colour="Negative", size = 2), hrc4) + theme(text = element_text(size=18))
ggplot() +
geom_line(aes(Date, Score, colour="Score", size = 2), hrc2) +
geom_line(aes(Date, Positive, colour="Positive", size = 2), hrc3) +
geom_line(aes(Date, Negative, colour="Negative", size = 2), hrc4)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive", size = 2), hrc3) +
geom_line(aes(Date, Negative, colour="Negative", size = 2), hrc4)
ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4)
hrc <- ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4)
hrc_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4)
hrc_plot
hrc_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4) + labs(title = "Sentiment of Hilary Clinton Tweets")
hrc_plot
source('~/GitHub/Sentiment Mining on Twitter/DJT Twitter.R', echo=TRUE)
djt_plot
grid.arrange(djt_plot, hrc_plot, ncol=2)
library(gridExtra)
grid.arrange(djt_plot, hrc_plot, ncol=2)
grid.arrange(djt_plot, hrc_plot, ncol=1)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + + labs(title = "Mean Sentiment Score of Clinton and Trump Related Tweets")
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of Clinton and Trump Related Tweets")
2_plots <- grid.arrange(djt_plot, hrc_plot, ncol=1)
plots <- grid.arrange(djt_plot, hrc_plot, ncol=1)
grid.arrange(plots, both_plot, ncol=1)
grid.arrange(plots, both_plot, ncol=2)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of Clinton/Trump Related Tweets")
plots <- grid.arrange(djt_plot, hrc_plot, ncol=1)
grid.arrange(plots, both_plot, ncol=2)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of
Clinton/Trump Related Tweets")
plots <- grid.arrange(djt_plot, hrc_plot, ncol=1)
grid.arrange(plots, both_plot, ncol=2)
hrc_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4) + labs(title = "Sentiment of Hilary Related Clinton Tweets")
djt_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Score"), size = 2, djt2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, djt3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, djt4) + labs(title = "Sentiment of Donald Related Trump Tweets")
library(gridExtra)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of
Clinton/Trump Related Tweets")
plots <- grid.arrange(djt_plot, hrc_plot, ncol=1)
grid.arrange(plots, both_plot, ncol=2)
grid.arrange(djt_plot, hrc_plot, both_plot, ncol=1)
grid.arrange(both_plot, hrc_plot, djt_plot, ncol=1)
hrc_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Average"), size = 2, hrc2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4) + labs(title = "Sentiment of Hilary Related Clinton Tweets")
djt_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Average"), size = 2, djt2) +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, djt3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, djt4) + labs(title = "Sentiment of Donald Related Trump Tweets")
library(gridExtra)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of
Clinton/Trump Related Tweets")
grid.arrange(both_plot, hrc_plot, djt_plot, ncol=1)
source('~/GitHub/Sentiment Mining on Twitter/Hillary Twitter.R', echo=TRUE)
source('~/GitHub/Sentiment Mining on Twitter/DJT Twitter.R', echo=TRUE)
library(gridExtra)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of
Clinton/Trump Related Tweets")
grid.arrange(both_plot, hrc_plot, djt_plot, ncol=1)
source('~/GitHub/Sentiment Mining on Twitter/Compare Plots.R', echo=TRUE)
require(wordcloud)
require(tm)
require(wordcloud)
require(tm)
require(RCurl)
require(twitteR)
require(ROAuth)
require(SnowballC)
require(ggplot2)
require(dplyr)
require(tidyr)
require(lubridate)
D1 <- Corpus(VectorSource(hrc$text))
require(tm)
install.packages("C:/Users/Chad/Downloads/slam_0.1-38.zip", repos = NULL, type = "win.binary")
require(wordcloud)
require(tm)
require(RCurl)
require(twitteR)
require(ROAuth)
require(SnowballC)
require(ggplot2)
require(dplyr)
require(tidyr)
require(lubridate)
D1 <- Corpus(VectorSource(hrc$text))
D2 <- sapply(D1,function(row) iconv(row, "latin1", "ASCII", sub=""))
## Remove Websites
D3 <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+@", "", D2)
## Remove spammed values by only selecting unique tweets
D5 <- Corpus(VectorSource(D3))
#########################
## Clean the corpus data
#########################
## Remove puncuation
D6 <- tm_map(D5, removePunctuation)
## Convert all characters to lower case
D6 <- tm_map(D5, content_transformer(tolower))
## Remove all stop words ("and" "the" "etc").
D6 <- tm_map(D5, removeWords, stopwords("english"))
## Remove numbers
D6 <- tm_map(D5, removeNumbers)
## Remove all the white space
D6 <- tm_map(D5, stripWhitespace)
## Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(D6)
##########################
# generate the word cloud
##########################
wordcloud(D6, max.words = 100, random.order = F, col= rainbow(20), scale = c(6, .5))
###################################################################
# Match words in corpus to lexicons of positive and negative words
###################################################################
## Upload positive and negative word lexicons
positive <- readLines("positive-words.txt")
negative <- readLines("negative-words.txt")
## Search for matches between each word and the two lexicons
hrc$positive <- tm_term_score(tdm.corpus, positive)
hrc$negative <- tm_term_score(tdm.corpus, negative)
hrc$score <- hrc$positive - hrc$negative
#########################################
# Generate graph for sentiment over time
#########################################
## Create data frame to graph
hrc2 <- hrc %>% group_by(created) %>% summarise(mean(score))
names(hrc2) <- c("Date", "Score")
hrc3 <- hrc %>% group_by(created) %>% summarise(mean(positive))
names(hrc3) <- c("Date", "Positive")
hrc4 <- hrc %>% group_by(created) %>% summarise(mean(negative))
names(hrc4) <- c("Date","Negative")
## Plot a line plot using ggplot
ggplot(hrc2, aes(Date, Score)) + geom_line() + xlab("Date") + ylab("Mean Sentiment Score")
hrc_plot <- ggplot() +
geom_line(aes(Date, Positive, colour="Positive"), size = 2, hrc3) +
geom_line(aes(Date, Negative, colour="Negative"), size = 2, hrc4) + labs(title = "Sentiment of Hilary Related Clinton Tweets")
source('~/GitHub/Sentiment Mining on Twitter/DJT Twitter.R', echo=TRUE)
library(gridExtra)
both_plot <- ggplot() +
geom_line(aes(Date, Score, colour="Clinton"), size = 2, hrc2) +
geom_line(aes(Date, Score, colour="Trump"), size = 2, djt2) + labs(title = "Mean Sentiment Score of
Clinton/Trump Related Tweets")
grid.arrange(both_plot, hrc_plot, djt_plot, ncol=1)
